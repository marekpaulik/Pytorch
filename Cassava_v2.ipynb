{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cassava2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9e1bcb6a310f425b81e4657d2ce26c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_158f10894b884bfeae79e8cb5aad491b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f2a04ece1df249de88c0ec205d627313",
              "IPY_MODEL_4f47c0fe15024f2baa2d8a7643e6a851"
            ]
          }
        },
        "158f10894b884bfeae79e8cb5aad491b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2a04ece1df249de88c0ec205d627313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9c54e25396ee48ac96217dc4af33d2b5",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 266860719,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 266860719,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f5eb19646fa4d6cb1749e4cef4068ff"
          }
        },
        "4f47c0fe15024f2baa2d8a7643e6a851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b43cd39128e44a2a8013774f335a1952",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 254M/254M [00:16&lt;00:00, 16.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1969afe79f3b4f02bca2438ee698fd64"
          }
        },
        "9c54e25396ee48ac96217dc4af33d2b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f5eb19646fa4d6cb1749e4cef4068ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b43cd39128e44a2a8013774f335a1952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1969afe79f3b4f02bca2438ee698fd64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marekpaulik/Pytorch/blob/main/Cassava_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECXORDZac7J7"
      },
      "source": [
        "! pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoQWIe3kc9H6",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "8816a498-12c9-448a-de08-10e2f18a8dc8"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ff530f83-5280-44e7-abae-b4a7531f0a4a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ff530f83-5280-44e7-abae-b4a7531f0a4a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"marekpaulik77\",\"key\":\"45a85395b9430e554cac34582f3daabb\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb7j9I27lJD4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "160c223a-7363-42e7-c3f4-16411c0f875f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6mY4iHSc9Kz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e0d1db-fcce-4621-e0a1-1b3338fe25df"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/e7/3bac01547d2ed3d308ac92a0878fbdb0ed0f3d41fb1906c319ccbba1bfbc/kaggle-1.5.12.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-cp37-none-any.whl size=73053 sha256=84deedb48d5342a287ecebfa67eed493244c4975cf80c3edb00823d3d374aae7\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/6a/26/d30b7499ff85a4a4593377a87ecf55f7d08af42f0de9b60303\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekS6nc0rc9NL",
        "outputId": "ebf176e2-c980-428e-b0fe-4e3f56648282"
      },
      "source": [
        "!kaggle competitions download -c cassava-disease"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading cassava-disease.zip to /content\n",
            "100% 2.30G/2.30G [00:29<00:00, 33.5MB/s]\n",
            "100% 2.30G/2.30G [00:29<00:00, 82.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeSpC-aPc9P_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2a8d70-4a43-465c-d20b-d27d498e7d78"
      },
      "source": [
        "! mkdir train\n",
        "! unzip cassava-disease.zip -d train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cassava-disease.zip\n",
            "  inflating: train/extraimages.zip   \n",
            "  inflating: train/random.txt        \n",
            "  inflating: train/sample_submission_file.csv  \n",
            "  inflating: train/test.zip          \n",
            "  inflating: train/train.zip         \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPBPe_Yqc9Ux"
      },
      "source": [
        "! unzip -q train/train.zip -d train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sj9OCqSesmk"
      },
      "source": [
        "! mkdir test\n",
        "! unzip -q train/test.zip -d test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm9TFGunrrGp",
        "outputId": "cbee610a-da95-409c-f6d7-e0b7a83ca243"
      },
      "source": [
        "! pip install efficientnet_pytorch --q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1AoMLP2dRXD"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import json\n",
        "from PIL import Image\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, WeightedRandomSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjIg-NaAjJvb"
      },
      "source": [
        "Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXGbO2JijLqz"
      },
      "source": [
        "# Early stopping\n",
        "class EarlyStopping:\n",
        "  def __init__(self, patience=3, delta=0, path='checkpoint.pt'):\n",
        "    self.patience = patience\n",
        "    self.delta = delta\n",
        "    self.path= path\n",
        "    self.counter = 0\n",
        "    self.best_score = None\n",
        "    self.early_stop = False\n",
        "\n",
        "  def __call__(self, val_loss, model):\n",
        "    if self.best_score is None:\n",
        "      self.best_score = val_loss\n",
        "      self.save_checkpoint(model)\n",
        "    elif val_loss > self.best_score:\n",
        "      self.counter +=1\n",
        "      if self.counter >= self.patience:\n",
        "        self.early_stop = True \n",
        "    else:\n",
        "      self.best_score = val_loss\n",
        "      self.save_checkpoint(model)\n",
        "      self.counter = 0      \n",
        "\n",
        "  def save_checkpoint(self, model):\n",
        "    torch.save(model.state_dict(), self.path)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xPKw0aiY9av"
      },
      "source": [
        "Load data (create dataloaders)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsvYhpcjqK6D"
      },
      "source": [
        "def load_data(data_dir, Transform, sample, batch_size):\n",
        "  ########################################################################################\n",
        "# data_dir - directory with images in subfolders, subfolders name are categories\n",
        "# Transform - data augmentations\n",
        "# sample - if the dataset is imbalanced set to true and RandomWeightedSampler will be used\n",
        "  #########################################################################################\n",
        "  train_full = torchvision.datasets.ImageFolder(data_dir, transform=Transform)\n",
        "  train_set, val_set = random_split(train_full, [math.floor(len(train_full)*0.8), math.ceil(len(train_full)*0.2)])\n",
        "\n",
        "  train_classes = [label for _, label in train_set]\n",
        "  if sample:\n",
        "    # Need to get weight for every image in the dataset\n",
        "    class_count = Counter(train_classes)\n",
        "    class_weights = torch.Tensor([len(train_classes)/c for c in pd.Series(class_count).sort_index().values]) # Cant iterate over class_count because dictionary is unordered\n",
        "\n",
        "    sample_weights = [0] * len(train_set)\n",
        "    for idx, (image, label) in enumerate(train_set):\n",
        "      class_weight = class_weights[label]\n",
        "      sample_weights[idx] = class_weight\n",
        "\n",
        "    sampler = WeightedRandomSampler(weights=sample_weights,\n",
        "                                    num_samples = len(train_set), replacement=True)  \n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, sampler=sampler)\n",
        "  else:\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  val_loader = DataLoader(val_set, batch_size=batch_size)\n",
        "\n",
        "  return train_loader, val_loader, train_classes    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M5OnWZIYupU"
      },
      "source": [
        "Load model, criterion, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULOTcIwRtsep"
      },
      "source": [
        "def load_model(arch, num_classes, lr, loss_weights, freeze_backbone, device, train_classes):\n",
        "  ########################################################################################\n",
        "# arch - choose the pretrained architecture from resnet or efficientnetb7\n",
        "# loss_weights - if the dataset is imbalanced set to true and weight parameter will be passed to loss function\n",
        "# freeze_backbone - if using pretrained architecture freeze all but the classification layer\n",
        "# train_classes - helper parameter passed from load_data(), needed if loss_weights=True\n",
        "  #########################################################################################  \n",
        "  if arch == 'resnet':\n",
        "    model = torchvision.models.resnet50(pretrained=True)\n",
        "    if freeze_backbone:\n",
        "      for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes)\n",
        "  elif arch == 'efficient-net':\n",
        "    model = EfficientNet.from_pretrained('efficientnet-b7')\n",
        "    if freeze_backbone:\n",
        "      for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    model._fc = nn.Linear(in_features=model._fc.in_features, out_features=num_classes)    \n",
        "\n",
        "  model = model.to(device)\n",
        "\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr) \n",
        "\n",
        "  if loss_weights:\n",
        "    class_count = Counter(train_classes)\n",
        "    class_weights = torch.Tensor([len(train_classes)/c for c in pd.Series(class_count).sort_index().values]) # Cant iterate over class_count because dictionary is unordered\n",
        "    class_weights = class_weights.to(device)  \n",
        "    criterion = nn.CrossEntropyLoss(class_weights)\n",
        "  else:\n",
        "    criterion = nn.CrossEntropyLoss() \n",
        "  \n",
        "  return model, optimizer, criterion   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbF0O2hZZnww"
      },
      "source": [
        "Train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6HUeuu811-S"
      },
      "source": [
        "def train(model, criterion, optimizer, num_epochs, use_amp, freeze_backbone,\n",
        "          unfreeze_after, tensorboard, stop_early, device, train_loader, val_loader):\n",
        "  if tensorboard:\n",
        "    writer = SummaryWriter('runs/sampler_cassava') #TODO parametrize\n",
        "  if stop_early:\n",
        "    early_stopping = EarlyStopping(\n",
        "    patience=5, \n",
        "    path='/content/drive/My Drive/ColabNotebooks/Cassava/sampler_checkpoint.pt') #TODO parametrize\n",
        "  \n",
        "  num_epochs = num_epochs\n",
        "  step_train = 0\n",
        "  step_val = 0\n",
        "\n",
        "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    if freeze_backbone:\n",
        "      if epoch == unfreeze_after:  # Unfreeze after x epochs\n",
        "        for param in model.parameters():\n",
        "          param.requires_grad = True\n",
        "\n",
        "    train_loss = list() # Every epoch check average loss per batch \n",
        "    train_acc = list()\n",
        "    model.train()\n",
        "    for i, (images, targets) in enumerate(tqdm(train_loader)):\n",
        "      images = images.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      with torch.cuda.amp.autocast(enabled=use_amp): #mixed precision\n",
        "        logits = model(images)\n",
        "        loss = criterion(logits, targets)\n",
        "\n",
        "      scaler.scale(loss).backward()\n",
        "      scaler.step(optimizer)\n",
        "      scaler.update()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      train_loss.append(loss.item())\n",
        "\n",
        "      #Calculate running train accuracy\n",
        "      predictions = torch.argmax(logits, dim=1)\n",
        "      num_correct = sum(predictions.eq(targets))\n",
        "      running_train_acc = float(num_correct) / float(images.shape[0])\n",
        "      train_acc.append(running_train_acc)\n",
        "\n",
        "      # Plot to tensorboard\n",
        "      if tensorboard:\n",
        "        img_grid = torchvision.utils.make_grid(images[:10])\n",
        "        writer.add_image('Cassava_images', img_grid) # Check how transformed images look in training\n",
        "        #writer.add_histogram('fc', model.fc.weight) # Check if our weights change during trianing\n",
        "\n",
        "        writer.add_scalar('training_loss', loss, global_step=step_train)\n",
        "        writer.add_scalar('training_acc', running_train_acc, global_step=step_train)\n",
        "        step_train +=1\n",
        "\n",
        "    print(f'Epoch {epoch}/{num_epochs-1}')  \n",
        "    print(f'Training loss: {torch.tensor(train_loss).mean():.2f}') \n",
        "\n",
        "    val_losses = list()\n",
        "    val_accs = list()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for (images, targets) in val_loader:\n",
        "        images = images.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast(enabled=use_amp):\n",
        "          logits = model(images)\n",
        "          loss = criterion(logits, targets)\n",
        "        val_losses.append(loss.item())      \n",
        "        \n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        num_correct = sum(predictions.eq(targets))\n",
        "        running_val_acc = float(num_correct) / float(images.shape[0])\n",
        "\n",
        "        val_accs.append(running_val_acc)\n",
        "        \n",
        "        if tensorboard:\n",
        "          writer.add_scalar('validation_loss', loss, global_step=step_val)\n",
        "          writer.add_scalar('validation_acc', running_val_acc, global_step=step_val)\n",
        "          step_val +=1\n",
        "\n",
        "      val_loss = torch.tensor(val_losses).mean()\n",
        "      val_acc = torch.tensor(val_accs).mean() # Average acc per batch\n",
        "      \n",
        "      print(f'Validation loss: {val_loss:.2f}')  \n",
        "      print(f'Validation accuracy: {val_acc:.2f}') \n",
        "      \n",
        "      if stop_early:\n",
        "        early_stopping(val_loss, model)\n",
        "        if early_stopping.early_stop:\n",
        "          print('Early Stopping')\n",
        "          print(f'Best validation loss: {early_stopping.best_score}')\n",
        "          break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxNy1rrX0SiO"
      },
      "source": [
        "def main(num_classes, device, data_dir='train/train', Transform=None, sample=False, loss_weights=False,\n",
        "         batch_size=64, lr=1e-4, arch='resnet', tensorboard=True,\n",
        "         stop_early=True, use_amp=True, freeze_backbone=True, num_epochs=10, unfreeze_after=5):\n",
        "  \n",
        "  train_loader, val_loader, train_classes = load_data(data_dir, Transform=Transform,\n",
        "                                       sample=sample, batch_size=batch_size)\n",
        "  \n",
        "  model, optimizer, criterion = load_model(arch=arch, num_classes=num_classes,\n",
        "                                lr=lr, loss_weights=loss_weights,\n",
        "                                freeze_backbone=freeze_backbone, device=device, train_classes=train_classes)\n",
        "\n",
        "  train(model=model, optimizer=optimizer, criterion=criterion, num_epochs=num_epochs, freeze_backbone=freeze_backbone,\n",
        "        unfreeze_after=unfreeze_after, tensorboard=tensorboard,\n",
        "        stop_early=stop_early, use_amp=use_amp, device=device, train_loader=train_loader,\n",
        "        val_loader=val_loader)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT-Um5k3AfIf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9e1bcb6a310f425b81e4657d2ce26c37",
            "158f10894b884bfeae79e8cb5aad491b",
            "f2a04ece1df249de88c0ec205d627313",
            "4f47c0fe15024f2baa2d8a7643e6a851",
            "9c54e25396ee48ac96217dc4af33d2b5",
            "5f5eb19646fa4d6cb1749e4cef4068ff",
            "b43cd39128e44a2a8013774f335a1952",
            "1969afe79f3b4f02bca2438ee698fd64"
          ]
        },
        "outputId": "f6968e04-f88c-4cbf-8ff3-f90d896b3d0c"
      },
      "source": [
        "Transform = T.Compose(\n",
        "    [T.ToTensor(),\n",
        "     T.Resize((256, 256)),\n",
        "     T.RandomRotation(90),\n",
        "     T.RandomHorizontalFlip(p=0.5),\n",
        "     T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "main(arch = 'efficient-net', Transform=Transform, sample=True, num_classes=5, device=device, num_epochs=20, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b7-dcc49843.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e1bcb6a310f425b81e4657d2ce26c37",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=266860719.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [08:01<00:00,  1.70s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/19\n",
            "Training loss: 1.54\n",
            "Validation loss: 1.45\n",
            "Validation accuracy: 0.52\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [07:58<00:00,  1.69s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/19\n",
            "Training loss: 1.42\n",
            "Validation loss: 1.36\n",
            "Validation accuracy: 0.55\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [07:56<00:00,  1.68s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/19\n",
            "Training loss: 1.35\n",
            "Validation loss: 1.30\n",
            "Validation accuracy: 0.58\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [08:00<00:00,  1.70s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/19\n",
            "Training loss: 1.29\n",
            "Validation loss: 1.23\n",
            "Validation accuracy: 0.58\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [07:59<00:00,  1.69s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/19\n",
            "Training loss: 1.25\n",
            "Validation loss: 1.19\n",
            "Validation accuracy: 0.59\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [17:52<00:00,  3.79s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/19\n",
            "Training loss: 0.78\n",
            "Validation loss: 0.55\n",
            "Validation accuracy: 0.81\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [17:50<00:00,  3.78s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/19\n",
            "Training loss: 0.46\n",
            "Validation loss: 0.54\n",
            "Validation accuracy: 0.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [17:50<00:00,  3.78s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/19\n",
            "Training loss: 0.37\n",
            "Validation loss: 0.51\n",
            "Validation accuracy: 0.84\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [17:52<00:00,  3.79s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/19\n",
            "Training loss: 0.30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/283 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.52\n",
            "Validation accuracy: 0.85\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [17:50<00:00,  3.78s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/19\n",
            "Training loss: 0.22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/283 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.51\n",
            "Validation accuracy: 0.86\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [17:52<00:00,  3.79s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/19\n",
            "Training loss: 0.20\n",
            "Validation loss: 0.48\n",
            "Validation accuracy: 0.86\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [17:50<00:00,  3.78s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11/19\n",
            "Training loss: 0.18\n",
            "Validation loss: 0.47\n",
            "Validation accuracy: 0.87\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [17:52<00:00,  3.79s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12/19\n",
            "Training loss: 0.15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/283 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.51\n",
            "Validation accuracy: 0.87\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [17:51<00:00,  3.79s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13/19\n",
            "Training loss: 0.12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/283 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.53\n",
            "Validation accuracy: 0.87\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [17:50<00:00,  3.78s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14/19\n",
            "Training loss: 0.12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/283 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.58\n",
            "Validation accuracy: 0.87\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [17:50<00:00,  3.78s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15/19\n",
            "Training loss: 0.12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/283 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.59\n",
            "Validation accuracy: 0.86\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 283/283 [17:49<00:00,  3.78s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16/19\n",
            "Training loss: 0.10\n",
            "Validation loss: 0.59\n",
            "Validation accuracy: 0.87\n",
            "Early Stopping\n",
            "Best validation loss: 0.4674777090549469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58B9bDflZ3Uy"
      },
      "source": [
        "# Plot an example\n",
        "def deprocess(img):\n",
        "  img = img.permute(1,2,0)\n",
        "  img = img * torch.Tensor([0.229, 0.224, 0.225]) + torch.Tensor([0.485, 0.456, 0.406])\n",
        "  return img\n",
        "\n",
        "\n",
        "images, targets = next(iter(train_loader))\n",
        "\n",
        "img = images[0]\n",
        "\n",
        "plt.imshow(deprocess(img))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I7Wv4MBtkWR"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSSZAXud6zBy"
      },
      "source": [
        "Plot Validation set predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYQ6sVg762RB"
      },
      "source": [
        "# Plots predictions on last batch\n",
        "# Does this work after changes?\n",
        "\n",
        "\n",
        "mapping = {0:'cbb', 1:'cbsd', 2:'cgm', 3:'cmd', 4:'healthy'}\n",
        "\n",
        "fig = plt.figure(figsize=(20,15))\n",
        "images = images.to('cpu')\n",
        "\n",
        "for i in range(len(images)):\n",
        "  ax = fig.add_subplot(4,4, i+1)\n",
        "  plt.imshow(deprocess(images[i]))\n",
        "  pred = pd.Series(predictions.to('cpu').numpy()).map(mapping)[i]\n",
        "  label = pd.Series(targets.to('cpu').numpy()).map(mapping)[i]\n",
        "  ax.set_title(f'Prediction: {pred} \\n Label: {label}',\n",
        "                    color=('green' if pred==label else 'red'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IhtYNoZscIw"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDIvXjw56CFE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "af179c81-b452-4677-db44-abefd294e209"
      },
      "source": [
        "model = load_state_dict(torch.load('/content/drive/My Drive/ColabNotebooks/Cassava/sampler_checkpoint.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e17889bfabc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/ColabNotebooks/Cassava/sampler_checkpoint.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'load_state_dict' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrsCb1u3o8_8"
      },
      "source": [
        "class Cassava_Test(Dataset):\n",
        "  def __init__(self, dir, transform=None):\n",
        "    self.dir = dir\n",
        "    self.transform = transform\n",
        "\n",
        "    self.images = os.listdir(self.dir)  \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = Image.open(os.path.join(self.dir, self.images[idx]))\n",
        "    return self.transform(img), self.images[idx]    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UohoEBA8pWT2"
      },
      "source": [
        "test_set = Cassava_Test('test/test/0', transform=Transform)\n",
        "test_loader = DataLoader(test_set, batch_size=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaclvaIYdc0y"
      },
      "source": [
        "sub = pd.DataFrame(columns=['category', 'id'])\n",
        "id_list = []\n",
        "pred_list = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  for (image, image_id) in test_loader:\n",
        "    image = image.to(device)\n",
        "\n",
        "    logits = model(image)\n",
        "    predicted = list(torch.argmax(logits, 1).cpu().numpy())\n",
        "\n",
        "    for id in image_id:\n",
        "      id_list.append(id)\n",
        "  \n",
        "    for prediction in predicted:\n",
        "      pred_list.append(prediction)\n",
        "sub['category'] = pred_list\n",
        "sub['id'] = id_list\n",
        "     \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrRQayPni7jL"
      },
      "source": [
        "#mapping = {0:'cbb', 1:'cbsd', 2:'cgm', 3:'cmd', 4:'healthy'}\n",
        "\n",
        "sub['category'] = sub['category'].map(mapping)\n",
        "sub = sub.sort_values(by='id')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFJ4Ib8VkqiU"
      },
      "source": [
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYpPtw70k_OF"
      },
      "source": [
        "sub.to_csv('Cassava_sub.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS0PWR47tOfU"
      },
      "source": [
        "GIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFb3qcY4tfBm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}